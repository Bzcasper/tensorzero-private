# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                   MODELS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[models.llama3_1_8b]
routing = ["groq"]

[models.llama3_1_8b.providers.groq]
type = "groq"
model_name = "meta-llama/llama-3.1-8b-instruct"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                 FUNCTIONS                                  │
# └────────────────────────────────────────────────────────────────────────────┘

[functions.simple_llm_call]
type = "chat"

[functions.simple_llm_call.variants.baseline]
type = "chat_completion"
model = "llama3_1_8b"

# ┌────────────────────────────────────────────────────────────────────────────┐
# │                                  METRICS                                   │
# └────────────────────────────────────────────────────────────────────────────┘

[metrics.task_success]
type = "boolean"
optimize = "max"
level = "episode"
